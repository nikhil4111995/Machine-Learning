{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk comes with a bunch of data sets that are necessary in order for it to operate in certain ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download_shell()\n",
    "#if you want see the list of packages first enter l and then to downlowad enter d and name of the packgae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The UCI is University of California Irvine and they actually have a machine learning repository with \n",
    "#a bunch of data sets that you can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are going to be using spam dataset to built a spam detection filter with Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.strip method removes the character passed as an argument in .strip function. If nothing is passed, it will remove the\n",
    "#whitespace based on the space given as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [line.strip() for line in open('/Users/nikhilraizada/Downloads/Refactored_Py_DS_ML_Bootcamp-master/20-Natural-Language-Processing/smsspamcollection/SMSSpamCollection')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5574\n"
     ]
    }
   ],
   "source": [
    "print(len(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham\\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A collection of text as you've mentioned is sometimes called a corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's go in and print out the first 10 messages and number them using enumerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for mess_num,message in enumerate(messages[:10]):\n",
    "    print(mess_num,messages)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham\\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this indicates that this is a tab separation instead of just parsing the TSV or tab separated files manually using Python.\n",
    "#We can just take advantage of our panel's knowledge in order to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sep is separator\n",
    "messages= pd.read_csv('/Users/nikhilraizada/Downloads/Refactored_Py_DS_ML_Bootcamp-master/20-Natural-Language-Processing/smsspamcollection/SMSSpamCollection',sep='\\t',names=['label','messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                           messages\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now do some exploratory data analysis of some data visualization and some statistical information about our \n",
    "#data to quickly check the stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                messages\n",
       "count   5572                    5572\n",
       "unique     2                    5169\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4825                      30"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">messages</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825</td>\n",
       "      <td>4516</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>653</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      messages                                                               \n",
       "         count unique                                                top freq\n",
       "label                                                                        \n",
       "ham       4825   4516                             Sorry, I'll call later   30\n",
       "spam       747    653  Please call our customer service representativ...    4"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With natural language processing. A large part of this is going to be feature engineering.The better your \n",
    "#domain knowledge on the data the better your ability to engineer more features from it and feature engineering \n",
    "#is a very large part of spam detection in general and I encourage you to read up on the topic by clicking the \n",
    "#link shown in the Jupiter notebook for this lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new column of length of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying built in lenght function on messages dataframe where column is also messages\n",
    "messages['length'] = messages['messages'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>messages</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                           messages  length\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111\n",
       "1   ham                      Ok lar... Joking wif u oni...      29\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
       "3   ham  U dun say so early hor... U c already then say...      49\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's visualise the length of the messages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f90fdb51cd0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages['length'].plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>80.489950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>59.942907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>122.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>910.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            length\n",
       "count  5572.000000\n",
       "mean     80.489950\n",
       "std      59.942907\n",
       "min       2.000000\n",
       "25%      36.000000\n",
       "50%      62.000000\n",
       "75%     122.000000\n",
       "max     910.000000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>messages</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>ham</td>\n",
       "      <td>For me the love should start with attraction.i...</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                           messages  length\n",
       "1085   ham  For me the love should start with attraction.i...     910"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages[messages['length']==910]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"For me the love should start with attraction.i should feel that I need her every time around me.she should be the first thing which comes in my thoughts.I would start the day and end it with her.she should be there every time I dream.love will be then when my every breath has her name.my life should happen around her.my life will be named to her.I would cry for her.will give all my happiness and take all her sorrows.I will be ready to fight with anyone for her.I will be in love when I will be doing the craziest things for her.love will be when I don't have to proove anyone that my girl is the most beautiful lady on the whole planet.I will always be singing praises for her.love will be when I start up making chicken curry and end up makiing sambar.life will be the most beautiful then.will get every morning and thank god for the day because she is with me.I would like to say a lot..will tell later..\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#after the above code line we are grabbing messgae column \n",
    "messages[messages['length']==910]['messages'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x7f90ff307e10>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x7f90ff09eed0>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#by is actually creating subplots of categorical column\n",
    "messages.hist(column='length',by='label',bins=60,figsize=(12,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#length is on x-axis\n",
    "#And what's very interesting here is just through basic exploratory data analysis we've been able to\n",
    "#discover a trend that spam messages tend to have more characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To conclude as we've seen here just visually it looks like length is a good feature to distinguish a spam message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mess = 'Sample message! Notice: It has punctuation.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "nopunc = [c for c in mess if c not in string.punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S',\n",
       " 'a',\n",
       " 'm',\n",
       " 'p',\n",
       " 'l',\n",
       " 'e',\n",
       " ' ',\n",
       " 'm',\n",
       " 'e',\n",
       " 's',\n",
       " 's',\n",
       " 'a',\n",
       " 'g',\n",
       " 'e',\n",
       " ' ',\n",
       " 'N',\n",
       " 'o',\n",
       " 't',\n",
       " 'i',\n",
       " 'c',\n",
       " 'e',\n",
       " ' ',\n",
       " 'I',\n",
       " 't',\n",
       " ' ',\n",
       " 'h',\n",
       " 'a',\n",
       " 's',\n",
       " ' ',\n",
       " 'p',\n",
       " 'u',\n",
       " 'n',\n",
       " 'c',\n",
       " 't',\n",
       " 'u',\n",
       " 'a',\n",
       " 't',\n",
       " 'i',\n",
       " 'o',\n",
       " 'n']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nopunc\n",
    "#But notice now it's removed and left as a blank all the punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sample message Notice It has punctuation'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nopunc = \"\".join(nopunc)\n",
    "nopunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')\n",
    "#we have downloaded this words above. These are very common english words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= ['a','b','c','d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcd'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sample', 'message', 'Notice', 'It', 'has', 'punctuation']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nopunc.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_mess = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sample', 'message', 'Notice', 'punctuation']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_mess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(mess):\n",
    "    \"\"\"\n",
    "    1. remove punctuation\n",
    "    2. remove stopwords\n",
    "    3.return list of clean text words\n",
    "    \"\"\"\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "    \n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>messages</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                           messages  length\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111\n",
       "1   ham                      Ok lar... Joking wif u oni...      29\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
       "3   ham  U dun say so early hor... U c already then say...      49\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Go, jurong, point, crazy, Available, bugis, n...\n",
       "1                       [Ok, lar, Joking, wif, u, oni]\n",
       "2    [Free, entry, 2, wkly, comp, win, FA, Cup, fin...\n",
       "3        [U, dun, say, early, hor, U, c, already, say]\n",
       "4    [Nah, dont, think, goes, usf, lives, around, t...\n",
       "Name: messages, dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['messages'].head(5).apply(text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's lots of ways to continue to normalize this text data. We actually have only done very simple text \n",
    "#normalization in pre-processing and the nltk library has lots of built in tools and great documentation on a \n",
    "#lot of other methods of normalization for example :stemming\n",
    "#What stemming does: If your text has a bunch of similar words such as running,ran and run. Stemming breaks down\n",
    "#all of these and returns run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And currently we have the messages as lists of tokens and now we need to convert each of those messages\n",
    "#into a vector that scikit learns algorithm models can work with.We're going to do, is convert each\n",
    "#message which is again represented by a list of tokens into a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are also ftting on our messages data\n",
    "bow_transformer = CountVectorizer(analyzer=text_process).fit(messages['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11425\n"
     ]
    }
   ],
   "source": [
    "#it will print the total number of vocab words\n",
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take one sample text message and get it's bag of words count as a vector putting to use our new bow_transformer.\n",
    "#Our bag of words transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grabbing the 4th message from our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "mess4 = messages['messages'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U dun say so early hor... U c already then say...\n"
     ]
    }
   ],
   "source": [
    "print(mess4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bow=bag of words\n",
    "bow4 = bow_transformer.transform([mess4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4068)\t2\n",
      "  (0, 4629)\t1\n",
      "  (0, 5261)\t1\n",
      "  (0, 6204)\t1\n",
      "  (0, 6222)\t1\n",
      "  (0, 7186)\t1\n",
      "  (0, 9554)\t2\n"
     ]
    }
   ],
   "source": [
    "print(bow4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 11425)\n"
     ]
    }
   ],
   "source": [
    "print(bow4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'U'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_transformer.get_feature_names()[4068]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'say'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_transformer.get_feature_names()[9554]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform entire dataframe messages into bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_bow = bow_transformer.transform(messages['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (5572, 11425)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Sparse Matrix: ',messages_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the amount of non-zeroes occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50548"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_bow.nnz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the sparsity\n",
    "#below code is copied code from notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 0\n"
     ]
    }
   ],
   "source": [
    "sparsity = (100.0 * messages_bow.nnz / (messages_bow.shape[0] * messages_bow.shape[1]))\n",
    "print('sparsity: {}'.format(round(sparsity)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 0.07940295412668218\n"
     ]
    }
   ],
   "source": [
    "sparsity = (100.0 * messages_bow.nnz / (messages_bow.shape[0] * messages_bow.shape[1]))\n",
    "print('sparsity: {}'.format(sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can see the true sparsity which is 0.079 and this is basically just comparing the number of non-zeros\n",
    "#messages versus the actual total number of messages. And this kind of gives you an idea of just how many zeros \n",
    "#there are in your actual matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that we've done the counting. The term weights and normalization can be done with TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer().fit(messages_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf4 = tfidf.transform(bow4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 9554)\t0.5385626262927564\n",
      "  (0, 7186)\t0.4389365653379857\n",
      "  (0, 6222)\t0.3187216892949149\n",
      "  (0, 6204)\t0.29953799723697416\n",
      "  (0, 5261)\t0.29729957405868723\n",
      "  (0, 4629)\t0.26619801906087187\n",
      "  (0, 4068)\t0.40832589933384067\n"
     ]
    }
   ],
   "source": [
    "print(tfidf4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So we've been able to transform just a simple word count into an actual tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we are going to check the inverse document frequency of the particular word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.527076498901426"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.idf_[bow_transformer.vocabulary_['university']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now converting the entire bag of words corpus into a tfidf corpus at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_tfidf = tfidf.transform(messages_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#But now that we finally have the messages represented as numerical vectors as we've seen here we can\n",
    "#finally train our spam ham classifier and we can actually use pretty much any sort of classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For a variety of reasons the naive base classifier algorithm is a good choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.fit first argument message_tfidf which we just created and message['label'] is the actual data\n",
    "spam_detect_model = MultinomialNB().fit(message_tfidf,messages['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#firstly trying to classifying the single random message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham'], dtype='<U4')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_detect_model.predict(tfidf4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_detect_model.predict(tfidf4)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['label'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to run prediction on all the messages in tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred = spam_detect_model.predict(messages_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'ham', 'spam', ..., 'ham', 'ham', 'ham'], dtype='<U4')"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our features are messages themselves\n",
    "\n",
    "msg_train,msg_test,label_train,label_test = train_test_split(messages['messages'],messages['label'],test_size=0.3,random_state =101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4028        Yes, princess. Are you going to make me moan?\n",
       "1310              Ok, be careful ! Don't text and drive !\n",
       "5469                                              Ok lor.\n",
       "5375    I cant pick the phone right now. Pls send a me...\n",
       "3814                Pls i wont belive god.not only jesus.\n",
       "                              ...                        \n",
       "4171    Mmmmmm ... I love you,so much, Ahmad ... I can...\n",
       "599     Will do. Was exhausted on train this morning. ...\n",
       "1361    Yo dude guess who just got arrested the other day\n",
       "1547                Shant disturb u anymore... Jia you...\n",
       "4959                     Why didn't u call on your lunch?\n",
       "Name: messages, Length: 3900, dtype: object"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For all the steps which we just did above, we can do it with the sckit learn pipeline features so you don't have\n",
    "#to constantly repeat everything for different sets of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list takes the steps argument in the Pipeline\n",
    "#in the list tuple takes in name of the step and the what you actually want to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    #And the next step was take those integer counts two weigh tfidf scores.\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "   #finally actually want to train this on my model\n",
    "    ('classifier',MultinomialNB())\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('bow',\n",
       "                 CountVectorizer(analyzer=<function text_process at 0x7f90e37a77a0>,\n",
       "                                 binary=False, decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('classifier',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is going to do the above three steps in the pipeline \n",
    "#instead of having to do it all manually yourself now you can just use pipeline in order to quickly and\n",
    "#succinctly do all that.\n",
    "pipeline.fit(msg_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(msg_test)\n",
    "#Luckily for you you just have to pass in the actual text data.\n",
    "#You no longer have to worry about manually doing the count vectorization or the tfidf transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98      1475\n",
      "        spam       1.00      0.65      0.79       197\n",
      "\n",
      "    accuracy                           0.96      1672\n",
      "   macro avg       0.98      0.83      0.88      1672\n",
      "weighted avg       0.96      0.96      0.96      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(label_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The 96 percent accuracy or precision and recall which is pretty good considering that we're just dealing\n",
    "#with straight text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we could have used the other classifier as well ex: Random forest considering which will give us good results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally: In the real world data, we are not going to do the steps which we did before the pipeline above. We will\n",
    "#only be building pipelines, do the count vectorization do the transformation and then call whatever model you want\n",
    "#and protects data. It should probably be multinomial and be depending on what you're working with and then just \n",
    "#call this pipeline as if it was the estimator that you created so pipelined that fit pipelined that predict etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
